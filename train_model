import pandas as pd
import numpy as np
import os
import time
import matplotlib.pyplot as plt
import cv2
import seaborn
seaborn.set_style('darkgrid')
import shutil
from sklearn.metrics import confusion_matrix, classification_report
from sklearn.model_selection import train_test_split
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.layers import Dense, Activation,Dropout,Conv2D, MaxPooling2D,BatchNormalization,ReLU
from tensorflow.keras.optimizers import Adam, Adamax
from tensorflow.keras.metrics import categorical_crossentropy
from tensorflow.keras import regularizers
from tensorflow.keras.models import Model
from tensorflow.keras import backend as K
import time
from sklearn.metrics import f1_score
import scipy.stats as stats
import sys
if not sys.warnoptions:
    import warnings
    warnings.simplefilter("ignore")
pd.set_option('display.max_columns', None)
pd.set_option('display.max_rows', None)
pd.set_option('display.max_colwidth', None)



#   ---------load data
# This is the kaggle dataset path
datapath=r'./attack_input/labels.csv'
imgpath=r'./attack_input/eps5'

# datapath=r'pizza_data/labels.csv'
# imgpath=r'pizza_data/images'
df=pd.read_csv(datapath)
df=df.sample(n=9123, replace=False, random_state = 1)
df['plain']=0
columns=df.columns

df['image_name']=df['image_name'].apply(lambda x: os.path.join(imgpath,x))
df = df.rename(columns={'image_name': 'filepaths'})

for i in range (len(df)):
    label_list=[]
    for j in range (1,len(df.columns)-1):
        column=df.columns[j]        
        label=df.iloc[i][column]
        label_list.append(label)
    max=np.max(label_list)        
    if max == 0:         
        df['plain'].iloc[i]=1
train_df, dummy_df=train_test_split(df, train_size=.8, shuffle=True, random_state=123)
valid_df, test_df=train_test_split(dummy_df, train_size=.5, shuffle=True, random_state=123)
print('train_df length: ', len(train_df), '  test_df length: ', len(test_df), '  valid_df length: ', len(valid_df)) 
img_size=(300,300)
columns=df.columns[1:]
class_count=len(columns)
generator=ImageDataGenerator()
train=generator.flow_from_dataframe(train_df, x_col='filepaths', y_col=columns, target_size=img_size, batch_size=30,shuffle=True,seed=123, class_mode='raw')
val=generator.flow_from_dataframe(valid_df, x_col='filepaths', y_col=columns, target_size=img_size, batch_size=30,shuffle=False,class_mode='raw')
test=generator.flow_from_dataframe(valid_df, x_col='filepaths', y_col=columns, target_size=img_size, batch_size=30,shuffle=False,class_mode='raw')



lr=.001
# model=VOneNet()
# model=VOneNet_with_four_GFBs()
# model=VOneNet_with_eight_GFBs()
model=VOneNet_with_Only_Simple_GFBs()
# model=EfficientNet_B0_Dense1024(img_size, lr, class_count)
epoch = 10
history=model.fit(x=train,  epochs=epochs, verbose=1, validation_data=val, shuffle=True,  initial_epoch=0)