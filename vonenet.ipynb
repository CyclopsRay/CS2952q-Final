{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"\n","metadata":{}},{"cell_type":"markdown","source":"# <center>A modified visual system simulation model improves the robustness of white box adversarial attack (VoneNet)</center>\n# <center> Team Member: Shilong Wu, Yinglong Li, Jingze Liu, Yuqi Lei</center>","metadata":{}},{"cell_type":"markdown","source":"# <center>Import Library</center>","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport os\nimport time\nimport matplotlib.pyplot as plt\nimport cv2\nimport seaborn\nseaborn.set_style('darkgrid')\nimport shutil\nfrom sklearn.metrics import confusion_matrix, classification_report\nfrom sklearn.model_selection import train_test_split\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.layers import Dense, Activation,Dropout,Conv2D, MaxPooling2D,BatchNormalization,ReLU\nfrom tensorflow.keras.optimizers import Adam, Adamax\nfrom tensorflow.keras.metrics import categorical_crossentropy\nfrom tensorflow.keras import regularizers\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras import backend as K\nimport time\nfrom sklearn.metrics import f1_score\nimport scipy.stats as stats\nimport sys\nif not sys.warnoptions:\n    import warnings\n    warnings.simplefilter(\"ignore\")\npd.set_option('display.max_columns', None)\npd.set_option('display.max_rows', None)\npd.set_option('display.max_colwidth', None)","metadata":{"execution":{"iopub.status.busy":"2023-05-07T02:08:12.113779Z","iopub.execute_input":"2023-05-07T02:08:12.114452Z","iopub.status.idle":"2023-05-07T02:08:12.125652Z","shell.execute_reply.started":"2023-05-07T02:08:12.114408Z","shell.execute_reply":"2023-05-07T02:08:12.124626Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# <center>EfficientNet_B0_1024 Model</center>","metadata":{}},{"cell_type":"code","source":"def EfficientNet_B0_Dense1024(img_size, lr, class_count):  \n    img_shape=(img_size[0], img_size[1], 3)\n    base_model=tf.keras.applications.efficientnet.EfficientNetB0(include_top=False, weights=\"imagenet\",input_shape=img_shape, pooling='max')\n    base_model.trainable=True\n    x=base_model.output\n    x=BatchNormalization(axis=-1, momentum=0.99, epsilon=0.001 )(x)\n    x=Dense(1024,activation='relu')(x)\n    output=Dense(class_count, activation='sigmoid')(x)\n    model=Model(inputs=base_model.input, outputs=output)\n    model.compile(Adamax(learning_rate=lr), loss='binary_crossentropy', metrics=['accuracy']) \n    return model","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# <center>Basic VoneNet</center>","metadata":{}},{"cell_type":"code","source":"def gabor_kernel(frequency, sigma_x, sigma_y, theta=0, offset=0, ks=61):\n    w = ks // 2\n    grid_val = tf.range(-w, w+1, dtype=tf.float32)\n    x, y = tf.meshgrid(grid_val, grid_val)\n    rotx = x * np.cos(theta) + y * np.sin(theta)\n    roty = -x * np.sin(theta) + y * np.cos(theta)\n    g = tf.exp(-0.5 * (rotx ** 2 / sigma_x ** 2 + roty ** 2 / sigma_y ** 2))\n    g /= 2 * np.pi * sigma_x * sigma_y\n    g *= tf.cos(2 * np.pi * frequency * rotx + offset)\n\n    return g\n\n\nclass Identity(layers.Layer):\n    def call(self, inputs):\n        return inputs\n\n\nclass GFB(layers.Layer):\n    def __init__(self, in_channels, out_channels, kernel_size, stride=4):\n        super().__init__()\n        self.in_channels = in_channels\n        self.out_channels = out_channels\n        self.kernel_size = kernel_size\n        self.stride = stride\n\n        self.weight = tf.Variable(tf.zeros(\n            (kernel_size, kernel_size, in_channels, out_channels)), trainable=False)\n\n    def call(self, inputs):\n        return tf.nn.conv2d(inputs, self.weight, strides=[1, self.stride, self.stride, 1], padding='SAME')\n\n    def initialize(self, sf, theta, sigx, sigy, phase):\n        random_channel = tf.random.uniform(\n            (self.out_channels,), minval=0, maxval=self.in_channels, dtype=tf.int32)\n#         for i in range(self.out_channels):\n#             self.weight[i, random_channel[i]] = gabor_kernel(frequency=sf[i], sigma_x=sigx[i], sigma_y=sigy[i],\n#                                                              theta=theta[i], offset=phase[i], ks=self.kernel_size)\n#         self.weight.assign(self.weight)\n        for i in range(self.out_channels):\n            gabor = gabor_kernel(frequency=sf[i], sigma_x=sigx[i], sigma_y=sigy[i],\n                                     theta=theta[i], offset=phase[i], ks=self.kernel_size)\n\n            # 使用scatter_nd_update更新权重\n#             tensor_i = tf.constant(i, dtype=tf.int32)  # 将 i 转换为张量\n#             indices = tf.constant([[tensor_i, random_channel[i]]], dtype=tf.int32)\n# #             indices = tf.constant([[i, random_channel[i]]], dtype=tf.int32)\n#             updates = tf.expand_dims(gabor, axis=0)\n#             self.weight = tf.tensor_scatter_nd_update(self.weight, indices, updates)\n#             tensor_i = tf.constant(i, dtype=tf.int32)  # 将 i 转换为张量\n#             tensor_channel = tf.constant(random_channel[i], dtype=tf.int32)  # 将 random_channel[i] 转换为张量\n#             indices = tf.expand_dims(tf.stack([tensor_i, tensor_channel]), axis=0)  # 堆叠张量并增加维度\n#             updates = tf.expand_dims(gabor, axis=0)\n#             self.weight = tf.tensor_scatter_nd_update(self.weight, indices, updates)\n\n            kernel = gabor_kernel(frequency=sf[i], sigma_x=sigx[i], sigma_y=sigy[i],\n                                  theta=theta[i], offset=phase[i], ks=self.kernel_size)\n            self.weight[:, :, random_channel[i], i].assign(kernel)\n\nclass VOneBlock(layers.Layer):\n    def __init__(self, sf, theta, sigx, sigy, phase,\n                 k_exc=25, noise_mode=None, noise_scale=1, noise_level=1,\n                 simple_channels=128, complex_channels=128, ksize=25, stride=4, input_size=224):\n        super().__init__()\n\n        self.in_channels = 3\n        self.simple_channels = simple_channels\n        self.complex_channels = complex_channels\n        self.out_channels = simple_channels + complex_channels\n        self.stride = stride\n        self.input_size = input_size\n\n        self.sf = sf\n        self.theta = theta\n        self.sigx = sigx\n        self.sigy = sigy\n        self.phase = phase\n        self.k_exc = k_exc\n\n        self.set_noise_mode(noise_mode, noise_scale, noise_level)\n        self.fixed_noise = None\n\n        self.simple_conv_q0 = GFB(\n            self.in_channels, self.out_channels, ksize, stride)\n        self.simple_conv_q1 = GFB(\n            self.in_channels, self.out_channels, ksize, stride)\n        self.simple_conv_q0.initialize(sf=self.sf, theta=self.theta, sigx=self.sigx, sigy=self.sigy,\n                                       phase=self.phase)\n        self.simple_conv_q1.initialize(sf=self.sf, theta=self.theta, sigx=self.sigx, sigy=self.sigy,\n                                       phase=self.phase + np.pi / 2)\n\n        self.simple = layers.ReLU()\n        self.complex = Identity()\n        self.gabors = Identity()\n        self.noise = layers.ReLU()\n        self.output_layer = Identity()\n\n    def call(self, inputs):\n        x = self.gabors_f(inputs)\n        x = self.noise_f(x)\n        x = self.output_layer(x)\n        return x\n\n    def gabors_f(self, inputs):\n        s_q0 = self.simple_conv_q0(inputs)\n        s_q1 = self.simple_conv_q1(inputs)\n        c = self.complex(tf.math.sqrt(s_q0[:, :, :, self.simple_channels:] ** 2 +\n                                      s_q1[:, :, :, self.simple_channels:] ** 2) / np.sqrt(2))\n        s = self.simple(s_q0[:, :, :, :self.simple_channels])\n\n        return self.gabors(self.k_exc * tf.concat((s, c), axis=-1))\n\n    def noise_f(self, inputs):\n        x = inputs\n        if self.noise_mode == 'neuronal':\n            eps = 10e-5\n            x *= self.noise_scale\n            x += self.noise_level\n            if self.fixed_noise is not None:\n                x += self.fixed_noise * tf.math.sqrt(tf.nn.relu(x) + eps)\n            else:\n                x += tf.random.normal(tf.shape(x), stddev=1) * \\\n                    tf.math.sqrt(tf.nn.relu(x) + eps)\n            x -= self.noise_level\n            x /= self.noise_scale\n        if self.noise_mode == 'gaussian':\n            if self.fixed_noise is not None:\n                x += self.fixed_noise * self.noise_scale\n            else:\n                x += tf.random.normal(tf.shape(x), stddev=1) * self.noise_scale\n        return self.noise(x)\n\n    def set_noise_mode(self, noise_mode=None, noise_scale=1, noise_level=1):\n        self.noise_mode = noise_mode\n        self.noise_scale = noise_scale\n        self.noise_level = noise_level\n\n    def fix_noise(self, batch_size=256, seed=None):\n        if seed:\n            tf.random.set_seed(seed)\n        noise_mean = tf.zeros((batch_size, int(\n            self.input_size / self.stride), int(self.input_size / self.stride), self.out_channels))\n        if self.noise_mode:\n            self.fixed_noise = tf.random.normal(noise_mean.shape, stddev=1)\n\n    def unfix_noise(self):\n        self.fixed_noise = None\n        \n    \ndef sample_dist(hist, bins, ns, scale='linear'):\n    rand_sample = np.random.rand(ns)\n    if scale == 'linear':\n        rand_sample = np.interp(\n            rand_sample, np.hstack(([0], hist.cumsum())), bins)\n    elif scale == 'log2':\n        rand_sample = np.interp(rand_sample, np.hstack(\n            ([0], hist.cumsum())), np.log2(bins))\n        rand_sample = 2**rand_sample\n    elif scale == 'log10':\n        rand_sample = np.interp(rand_sample, np.hstack(\n            ([0], hist.cumsum())), np.log10(bins))\n        rand_sample = 10**rand_sample\n    return rand_sample\n\n\ndef generate_gabor_param(features, seed=0, rand_flag=False, sf_corr=0, sf_max=9, sf_min=0):\n    # Generates random sample\n    np.random.seed(seed)\n\n    phase_bins = np.array([0, 360])\n    phase_dist = np.array([1])\n\n    if rand_flag:\n        print('Uniform gabor parameters')\n        ori_bins = np.array([0, 180])\n        ori_dist = np.array([1])\n\n        nx_bins = np.array([0.1, 10**0.2])\n        nx_dist = np.array([1])\n\n        ny_bins = np.array([0.1, 10**0.2])\n        ny_dist = np.array([1])\n\n        # sf_bins = np.array([0.5, 8])\n        # sf_dist = np.array([1])\n\n        sf_bins = np.array([0.5, 0.7, 1.0, 1.4, 2.0, 2.8, 4.0, 5.6, 8])\n        sf_dist = np.array([1,  1,  1, 1, 1, 1, 1, 1])\n\n        sfmax_ind = np.where(sf_bins < sf_max)[0][-1]\n        sfmin_ind = np.where(sf_bins >= sf_min)[0][0]\n\n        sf_bins = sf_bins[sfmin_ind:sfmax_ind+1]\n        sf_dist = sf_dist[sfmin_ind:sfmax_ind]\n\n        sf_dist = sf_dist / sf_dist.sum()\n    else:\n        print('Neuronal distributions gabor parameters')\n        # DeValois 1982a\n        ori_bins = np.array([-22.5, 22.5, 67.5, 112.5, 157.5])\n        ori_dist = np.array([66, 49, 77, 54])\n        ori_dist = ori_dist / ori_dist.sum()\n\n        # Schiller 1976\n        cov_mat = np.array([[1, sf_corr], [sf_corr, 1]])\n\n        # Ringach 2002b\n        nx_bins = np.logspace(-1, 0.2, 6, base=10)\n        ny_bins = np.logspace(-1, 0.2, 6, base=10)\n        n_joint_dist = np.array([[2.,  0.,  1.,  0.,  0.],\n                                 [8.,  9.,  4.,  1.,  0.],\n                                 [1.,  2., 19., 17.,  3.],\n                                 [0.,  0.,  1.,  7.,  4.],\n                                 [0.,  0.,  0.,  0.,  0.]])\n        n_joint_dist = n_joint_dist / n_joint_dist.sum()\n        nx_dist = n_joint_dist.sum(axis=1)\n        nx_dist = nx_dist / nx_dist.sum()\n        ny_dist_marg = n_joint_dist / n_joint_dist.sum(axis=1, keepdims=True)\n\n        # DeValois 1982b\n        sf_bins = np.array([0.5, 0.7, 1.0, 1.4, 2.0, 2.8, 4.0, 5.6, 8])\n        sf_dist = np.array([4,  4,  8, 25, 32, 26, 28, 12])\n\n        sfmax_ind = np.where(sf_bins <= sf_max)[0][-1]\n        sfmin_ind = np.where(sf_bins >= sf_min)[0][0]\n\n        sf_bins = sf_bins[sfmin_ind:sfmax_ind+1]\n        sf_dist = sf_dist[sfmin_ind:sfmax_ind]\n\n        sf_dist = sf_dist / sf_dist.sum()\n\n    phase = sample_dist(phase_dist, phase_bins, features)\n    ori = sample_dist(ori_dist, ori_bins, features)\n    ori[ori < 0] = ori[ori < 0] + 180\n\n    if rand_flag:\n        sf = sample_dist(sf_dist, sf_bins, features, scale='log2')\n        nx = sample_dist(nx_dist, nx_bins, features, scale='log10')\n        ny = sample_dist(ny_dist, ny_bins, features, scale='log10')\n    else:\n\n        samps = np.random.multivariate_normal([0, 0], cov_mat, features)\n        samps_cdf = stats.norm.cdf(samps)\n\n        nx = np.interp(samps_cdf[:, 0], np.hstack(\n            ([0], nx_dist.cumsum())), np.log10(nx_bins))\n        nx = 10**nx\n\n        ny_samp = np.random.rand(features)\n        ny = np.zeros(features)\n        for samp_ind, nx_samp in enumerate(nx):\n            bin_id = np.argwhere(nx_bins < nx_samp)[-1]\n            ny[samp_ind] = np.interp(ny_samp[samp_ind], np.hstack(([0], ny_dist_marg[bin_id, :].cumsum())),\n                                     np.log10(ny_bins))\n        ny = 10**ny\n\n        sf = np.interp(samps_cdf[:, 1], np.hstack(\n            ([0], sf_dist.cumsum())), np.log2(sf_bins))\n        sf = 2**sf\n\n    return sf, ori, phase, nx, ny\n\n\ndef VOneNet(sf_corr=0.75, sf_max=9, sf_min=0, rand_param=False, gabor_seed=0,\n            simple_channels=256, complex_channels=256,\n            noise_mode='neuronal', noise_scale=0.35, noise_level=0.07, k_exc=25,\n            model_arch='resnet50', image_size=300, visual_degrees=8, ksize=25, stride=4, class_count=14):\n\n    out_channels = simple_channels + complex_channels\n\n    sf, theta, phase, nx, ny = generate_gabor_param(\n        out_channels, gabor_seed, rand_param, sf_corr, sf_max, sf_min)\n\n    gabor_params = {'simple_channels': simple_channels, 'complex_channels': complex_channels, 'rand_param': rand_param,\n                    'gabor_seed': gabor_seed, 'sf_max': sf_max, 'sf_corr': sf_corr, 'sf': sf.copy(),\n                    'theta': theta.copy(), 'phase': phase.copy(), 'nx': nx.copy(), 'ny': ny.copy()}\n    arch_params = {'k_exc': k_exc, 'arch': model_arch,\n                   'ksize': ksize, 'stride': stride}\n\n    # Conversions\n    ppd = image_size / visual_degrees\n\n    sf = sf / ppd\n    sigx = nx / sf\n    sigy = ny / sf\n    theta = theta/180 * np.pi\n    phase = phase / 180 * np.pi\n\n    vone_block = VOneBlock(sf=sf, theta=theta, sigx=sigx, sigy=sigy, phase=phase,\n                           k_exc=k_exc, noise_mode=noise_mode, noise_scale=noise_scale, noise_level=noise_level,\n                           simple_channels=simple_channels, complex_channels=complex_channels,\n                           ksize=ksize, stride=stride, input_size=image_size)\n    \n    \n    \n    \n    img_shape=(image_size,image_size,3)\n#     model_back_end=tf.keras.applications.efficientnet.EfficientNetB0(include_top=False, weights=\"imagenet\",input_shape=img_shape, pooling='max')\n    \n#     inputs = tf.keras.Input(shape=(image_size, image_size, 3))\n#     x = vone_block(inputs)\n    \n    \n#     if model_arch:\n    bottleneck = Conv2D(3, kernel_size=1, strides=1, use_bias=False,kernel_initializer=tf.keras.initializers.HeNormal())\n\n#         # if model_arch.lower() == 'resnet50':\n#         #     print('Model: ', 'VOneResnet50')\n#         #     model_back_end = ResNetBackEnd(\n#         #         block=Bottleneck, layers=[3, 4, 6, 3])\n#         # elif model_arch.lower() == 'alexnet':\n#         #     print('Model: ', 'VOneAlexNet')\n#         #     model_back_end = AlexNetBackEnd()\n#         # elif model_arch.lower() == 'cornets':\n#         #     print('Model: ', 'VOneCORnet-S')\n#         #     model_back_end = CORnetSBackEnd()\n#         # TODO: change model_back_end to our block\n\n    inputs = tf.keras.Input(shape=(image_size, image_size, 3))\n    x = vone_block(inputs)\n    x = bottleneck(x)\n    \n    \n    # 获取模型后端的输入张量\n#     backend_input = model_back_end.input\n\n#     print(x.shape)\n#     assert(False)\n    \n    \n    model_back_end=tf.keras.applications.efficientnet.EfficientNetB0(include_top=False, weights=\"imagenet\",input_shape=x.shape[1:], pooling='max')\n    model_back_end.trainable = True\n#     print(backend_input.shape)\n\n    \n    # 用 bottleneck 的输出替换模型后端的输入张量\n    backend_output = model_back_end(x)\n    \n    \n    x=backend_output\n    x=BatchNormalization(axis=-1, momentum=0.99, epsilon=0.001 )(x)\n    x=Dense(1024,activation='relu')(x)\n    outputs=Dense(class_count, activation='sigmoid')(x)\n\n    \n#     outputs = model_back_end.output\n    model = Model(inputs=inputs, outputs=outputs)\n    model.compile(Adamax(learning_rate=0.01), loss='binary_crossentropy', metrics=['accuracy']) \n#     else:\n#         print('Model: ', 'VOneNet')\n#         model = vone_block\n\n    model.image_size = image_size\n    model.visual_degrees = visual_degrees\n    model.gabor_parms = gabor_params\n    model.arch_params = arch_params\n\n    return model\n\n\n\n","metadata":{"execution":{"iopub.status.busy":"2023-05-07T02:08:12.147897Z","iopub.execute_input":"2023-05-07T02:08:12.148797Z","iopub.status.idle":"2023-05-07T02:08:12.218217Z","shell.execute_reply.started":"2023-05-07T02:08:12.148754Z","shell.execute_reply":"2023-05-07T02:08:12.216971Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# <center>VOneNet_with_Only_Simple_GFBs</center>","metadata":{}},{"cell_type":"code","source":"\nclass VOneBlock_Only_Simple_GFBs(layers.Layer):\n    def __init__(self, sf, theta, sigx, sigy, phase,\n                 k_exc=25, noise_mode=None, noise_scale=1, noise_level=1,\n                 simple_channels=128, complex_channels=128, ksize=25, stride=4, input_size=224):\n        super().__init__()\n\n        self.in_channels = 3\n        self.simple_channels = simple_channels\n        self.complex_channels = complex_channels\n        self.out_channels = simple_channels + complex_channels\n        self.stride = stride\n        self.input_size = input_size\n\n        self.sf = sf\n        self.theta = theta\n        self.sigx = sigx\n        self.sigy = sigy\n        self.phase = phase\n        self.k_exc = k_exc\n\n        self.set_noise_mode(noise_mode, noise_scale, noise_level)\n        self.fixed_noise = None\n\n        self.simple_conv_q0 = GFB(\n            self.in_channels, self.out_channels, ksize, stride)\n        self.simple_conv_q1 = GFB(\n            self.in_channels, self.out_channels, ksize, stride)\n        \n        self.simple_conv_q0.initialize(sf=self.sf, theta=self.theta, sigx=self.sigx, sigy=self.sigy,\n                                       phase=self.phase)\n        self.simple_conv_q1.initialize(sf=self.sf, theta=self.theta, sigx=self.sigx, sigy=self.sigy,\n                                       phase=self.phase + np.pi / 2)\n\n        self.simple = layers.ReLU()\n        self.complex = Identity()\n        self.gabors = Identity()\n        self.noise = layers.ReLU()\n        self.output_layer = Identity()\n\n    def call(self, inputs):\n        x = self.gabors_f(inputs)\n        x = self.noise_f(x)\n        x = self.output_layer(x)\n        return x\n\n    def gabors_f(self, inputs):\n        s_q0 = self.simple_conv_q0(inputs)\n        s_q1 = self.simple_conv_q1(inputs)\n        c = self.complex(tf.math.sqrt(s_q0[:, :, :, self.simple_channels:] ** 2 +\n                                      s_q1[:, :, :, self.simple_channels:] ** 2 ) / np.sqrt(2))\n        s = self.simple(s_q0[:, :, :, :self.simple_channels])\n\n        return self.gabors(self.k_exc * s)\n\n    def noise_f(self, inputs):\n        x = inputs\n        if self.noise_mode == 'neuronal':\n            eps = 10e-5\n            x *= self.noise_scale\n            x += self.noise_level\n            if self.fixed_noise is not None:\n                x += self.fixed_noise * tf.math.sqrt(tf.nn.relu(x) + eps)\n            else:\n                x += tf.random.normal(tf.shape(x), stddev=1) * \\\n                    tf.math.sqrt(tf.nn.relu(x) + eps)\n            x -= self.noise_level\n            x /= self.noise_scale\n        if self.noise_mode == 'gaussian':\n            if self.fixed_noise is not None:\n                x += self.fixed_noise * self.noise_scale\n            else:\n                x += tf.random.normal(tf.shape(x), stddev=1) * self.noise_scale\n        return self.noise(x)\n\n    def set_noise_mode(self, noise_mode=None, noise_scale=1, noise_level=1):\n        self.noise_mode = noise_mode\n        self.noise_scale = noise_scale\n        self.noise_level = noise_level\n\n    def fix_noise(self, batch_size=256, seed=None):\n        if seed:\n            tf.random.set_seed(seed)\n        noise_mean = tf.zeros((batch_size, int(\n            self.input_size / self.stride), int(self.input_size / self.stride), self.out_channels))\n        if self.noise_mode:\n            self.fixed_noise = tf.random.normal(noise_mean.shape, stddev=1)\n\n    def unfix_noise(self):\n        self.fixed_noise = None\n\n        \n        \n        \n        \n        \n        \n\n\ndef VOneNet_with_Only_Simple_GFBs(sf_corr=0.75, sf_max=9, sf_min=0, rand_param=False, gabor_seed=0,\n            simple_channels=256, complex_channels=256,\n            noise_mode='neuronal', noise_scale=0.35, noise_level=0.07, k_exc=25,\n            model_arch='resnet50', image_size=300, visual_degrees=8, ksize=25, stride=4, class_count=14):\n\n    out_channels = simple_channels + complex_channels\n\n    sf, theta, phase, nx, ny = generate_gabor_param(\n        out_channels, gabor_seed, rand_param, sf_corr, sf_max, sf_min)\n\n    gabor_params = {'simple_channels': simple_channels, 'complex_channels': complex_channels, 'rand_param': rand_param,\n                    'gabor_seed': gabor_seed, 'sf_max': sf_max, 'sf_corr': sf_corr, 'sf': sf.copy(),\n                    'theta': theta.copy(), 'phase': phase.copy(), 'nx': nx.copy(), 'ny': ny.copy()}\n    arch_params = {'k_exc': k_exc, 'arch': model_arch,\n                   'ksize': ksize, 'stride': stride}\n\n    # Conversions\n    ppd = image_size / visual_degrees\n\n    sf = sf / ppd\n    sigx = nx / sf\n    sigy = ny / sf\n    theta = theta/180 * np.pi\n    phase = phase / 180 * np.pi\n\n    vone_block = VOneBlock_Only_Simple_GFBs(sf=sf, theta=theta, sigx=sigx, sigy=sigy, phase=phase,\n                           k_exc=k_exc, noise_mode=noise_mode, noise_scale=noise_scale, noise_level=noise_level,\n                           simple_channels=simple_channels, complex_channels=complex_channels,\n                           ksize=ksize, stride=stride, input_size=image_size)\n    \n    \n    \n    \n    img_shape=(image_size,image_size,3)\n#     model_back_end=tf.keras.applications.efficientnet.EfficientNetB0(include_top=False, weights=\"imagenet\",input_shape=img_shape, pooling='max')\n    \n#     inputs = tf.keras.Input(shape=(image_size, image_size, 3))\n#     x = vone_block(inputs)\n    \n    \n#     if model_arch:\n    bottleneck = Conv2D(3, kernel_size=1, strides=1, use_bias=False,kernel_initializer=tf.keras.initializers.HeNormal())\n\n#         # if model_arch.lower() == 'resnet50':\n#         #     print('Model: ', 'VOneResnet50')\n#         #     model_back_end = ResNetBackEnd(\n#         #         block=Bottleneck, layers=[3, 4, 6, 3])\n#         # elif model_arch.lower() == 'alexnet':\n#         #     print('Model: ', 'VOneAlexNet')\n#         #     model_back_end = AlexNetBackEnd()\n#         # elif model_arch.lower() == 'cornets':\n#         #     print('Model: ', 'VOneCORnet-S')\n#         #     model_back_end = CORnetSBackEnd()\n#         # TODO: change model_back_end to our block\n\n    inputs = tf.keras.Input(shape=(image_size, image_size, 3))\n    x = vone_block(inputs)\n    x = bottleneck(x)\n    \n    \n    # 获取模型后端的输入张量\n#     backend_input = model_back_end.input\n\n#     print(x.shape)\n#     assert(False)\n    \n    \n    model_back_end=tf.keras.applications.efficientnet.EfficientNetB0(include_top=False, weights=\"imagenet\",input_shape=x.shape[1:], pooling='max')\n    model_back_end.trainable = True\n#     print(backend_input.shape)\n\n    \n    # 用 bottleneck 的输出替换模型后端的输入张量\n    backend_output = model_back_end(x)\n    \n    \n    x=backend_output\n    x=BatchNormalization(axis=-1, momentum=0.99, epsilon=0.001 )(x)\n    x=Dense(1024,activation='relu')(x)\n    outputs=Dense(class_count, activation='sigmoid')(x)\n\n    \n#     outputs = model_back_end.output\n    model = Model(inputs=inputs, outputs=outputs)\n    model.compile(Adamax(learning_rate=0.01), loss='binary_crossentropy', metrics=['accuracy']) \n#     else:\n#         print('Model: ', 'VOneNet')\n#         model = vone_block\n\n    model.image_size = image_size\n    model.visual_degrees = visual_degrees\n    model.gabor_parms = gabor_params\n    model.arch_params = arch_params\n\n    return model\n","metadata":{"execution":{"iopub.status.busy":"2023-05-07T02:08:12.221617Z","iopub.execute_input":"2023-05-07T02:08:12.222346Z","iopub.status.idle":"2023-05-07T02:08:12.255475Z","shell.execute_reply.started":"2023-05-07T02:08:12.222293Z","shell.execute_reply":"2023-05-07T02:08:12.254352Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# <center>VOneNet_with_4_GFBs</center>","metadata":{}},{"cell_type":"code","source":"    \nclass VOneBlock_Four_GFBs(layers.Layer):\n    def __init__(self, sf, theta, sigx, sigy, phase,\n                 k_exc=25, noise_mode=None, noise_scale=1, noise_level=1,\n                 simple_channels=128, complex_channels=128, ksize=25, stride=4, input_size=224):\n        super().__init__()\n\n        self.in_channels = 3\n        self.simple_channels = simple_channels\n        self.complex_channels = complex_channels\n        self.out_channels = simple_channels + complex_channels\n        self.stride = stride\n        self.input_size = input_size\n\n        self.sf = sf\n        self.theta = theta\n        self.sigx = sigx\n        self.sigy = sigy\n        self.phase = phase\n        self.k_exc = k_exc\n\n        self.set_noise_mode(noise_mode, noise_scale, noise_level)\n        self.fixed_noise = None\n\n        self.simple_conv_q0 = GFB(\n            self.in_channels, self.out_channels, ksize, stride)\n        self.simple_conv_q1 = GFB(\n            self.in_channels, self.out_channels, ksize, stride)\n        self.simple_conv_q2 = GFB(\n            self.in_channels, self.out_channels, ksize, stride)\n        self.simple_conv_q3 = GFB(\n            self.in_channels, self.out_channels, ksize, stride)\n        \n        self.simple_conv_q0.initialize(sf=self.sf, theta=self.theta, sigx=self.sigx, sigy=self.sigy,\n                                       phase=self.phase)\n        self.simple_conv_q1.initialize(sf=self.sf, theta=self.theta, sigx=self.sigx, sigy=self.sigy,\n                                       phase=self.phase + np.pi / 4)\n        self.simple_conv_q2.initialize(sf=self.sf, theta=self.theta, sigx=self.sigx, sigy=self.sigy,\n                                       phase=self.phase + np.pi / 2)\n        self.simple_conv_q3.initialize(sf=self.sf, theta=self.theta, sigx=self.sigx, sigy=self.sigy,\n                                       phase=self.phase + np.pi * 3 / 4)\n\n        self.simple = layers.ReLU()\n        self.complex = Identity()\n        self.gabors = Identity()\n        self.noise = layers.ReLU()\n        self.output_layer = Identity()\n\n    def call(self, inputs):\n        x = self.gabors_f(inputs)\n        x = self.noise_f(x)\n        x = self.output_layer(x)\n        return x\n\n    def gabors_f(self, inputs):\n        s_q0 = self.simple_conv_q0(inputs)\n        s_q1 = self.simple_conv_q1(inputs)\n        s_q2 = self.simple_conv_q2(inputs)\n        s_q3 = self.simple_conv_q3(inputs)\n        c = self.complex(tf.math.sqrt(s_q0[:, :, :, self.simple_channels:] ** 2 +\n                                      s_q1[:, :, :, self.simple_channels:] ** 2 +\n                                      s_q2[:, :, :, self.simple_channels:] ** 2 +\n                                      s_q3[:, :, :, self.simple_channels:] ** 2) / np.sqrt(4))\n        s = self.simple(s_q0[:, :, :, :self.simple_channels])\n\n        return self.gabors(self.k_exc * tf.concat((s, c), axis=-1))\n\n    def noise_f(self, inputs):\n        x = inputs\n        if self.noise_mode == 'neuronal':\n            eps = 10e-5\n            x *= self.noise_scale\n            x += self.noise_level\n            if self.fixed_noise is not None:\n                x += self.fixed_noise * tf.math.sqrt(tf.nn.relu(x) + eps)\n            else:\n                x += tf.random.normal(tf.shape(x), stddev=1) * \\\n                    tf.math.sqrt(tf.nn.relu(x) + eps)\n            x -= self.noise_level\n            x /= self.noise_scale\n        if self.noise_mode == 'gaussian':\n            if self.fixed_noise is not None:\n                x += self.fixed_noise * self.noise_scale\n            else:\n                x += tf.random.normal(tf.shape(x), stddev=1) * self.noise_scale\n        return self.noise(x)\n\n    def set_noise_mode(self, noise_mode=None, noise_scale=1, noise_level=1):\n        self.noise_mode = noise_mode\n        self.noise_scale = noise_scale\n        self.noise_level = noise_level\n\n    def fix_noise(self, batch_size=256, seed=None):\n        if seed:\n            tf.random.set_seed(seed)\n        noise_mean = tf.zeros((batch_size, int(\n            self.input_size / self.stride), int(self.input_size / self.stride), self.out_channels))\n        if self.noise_mode:\n            self.fixed_noise = tf.random.normal(noise_mean.shape, stddev=1)\n\n    def unfix_noise(self):\n        self.fixed_noise = None\n\n        \n        \n        \n        \n        \n        \n\n\ndef VOneNet_with_four_GFBs(sf_corr=0.75, sf_max=9, sf_min=0, rand_param=False, gabor_seed=0,\n            simple_channels=256, complex_channels=256,\n            noise_mode='neuronal', noise_scale=0.35, noise_level=0.07, k_exc=25,\n            model_arch='resnet50', image_size=300, visual_degrees=8, ksize=25, stride=4, class_count=14):\n\n    out_channels = simple_channels + complex_channels\n\n    sf, theta, phase, nx, ny = generate_gabor_param(\n        out_channels, gabor_seed, rand_param, sf_corr, sf_max, sf_min)\n\n    gabor_params = {'simple_channels': simple_channels, 'complex_channels': complex_channels, 'rand_param': rand_param,\n                    'gabor_seed': gabor_seed, 'sf_max': sf_max, 'sf_corr': sf_corr, 'sf': sf.copy(),\n                    'theta': theta.copy(), 'phase': phase.copy(), 'nx': nx.copy(), 'ny': ny.copy()}\n    arch_params = {'k_exc': k_exc, 'arch': model_arch,\n                   'ksize': ksize, 'stride': stride}\n\n    # Conversions\n    ppd = image_size / visual_degrees\n\n    sf = sf / ppd\n    sigx = nx / sf\n    sigy = ny / sf\n    theta = theta/180 * np.pi\n    phase = phase / 180 * np.pi\n\n    vone_block = VOneBlock_Four_GFBs(sf=sf, theta=theta, sigx=sigx, sigy=sigy, phase=phase,\n                           k_exc=k_exc, noise_mode=noise_mode, noise_scale=noise_scale, noise_level=noise_level,\n                           simple_channels=simple_channels, complex_channels=complex_channels,\n                           ksize=ksize, stride=stride, input_size=image_size)\n    \n    \n    \n    \n    img_shape=(image_size,image_size,3)\n#     model_back_end=tf.keras.applications.efficientnet.EfficientNetB0(include_top=False, weights=\"imagenet\",input_shape=img_shape, pooling='max')\n    \n#     inputs = tf.keras.Input(shape=(image_size, image_size, 3))\n#     x = vone_block(inputs)\n    \n    \n#     if model_arch:\n    bottleneck = Conv2D(3, kernel_size=1, strides=1, use_bias=False,kernel_initializer=tf.keras.initializers.HeNormal())\n\n#         # if model_arch.lower() == 'resnet50':\n#         #     print('Model: ', 'VOneResnet50')\n#         #     model_back_end = ResNetBackEnd(\n#         #         block=Bottleneck, layers=[3, 4, 6, 3])\n#         # elif model_arch.lower() == 'alexnet':\n#         #     print('Model: ', 'VOneAlexNet')\n#         #     model_back_end = AlexNetBackEnd()\n#         # elif model_arch.lower() == 'cornets':\n#         #     print('Model: ', 'VOneCORnet-S')\n#         #     model_back_end = CORnetSBackEnd()\n#         # TODO: change model_back_end to our block\n\n    inputs = tf.keras.Input(shape=(image_size, image_size, 3))\n    x = vone_block(inputs)\n    x = bottleneck(x)\n    \n    \n    # 获取模型后端的输入张量\n#     backend_input = model_back_end.input\n\n#     print(x.shape)\n#     assert(False)\n    \n    \n    model_back_end=tf.keras.applications.efficientnet.EfficientNetB0(include_top=False, weights=\"imagenet\",input_shape=x.shape[1:], pooling='max')\n    model_back_end.trainable = True\n#     print(backend_input.shape)\n\n    \n    # 用 bottleneck 的输出替换模型后端的输入张量\n    backend_output = model_back_end(x)\n    \n    \n    x=backend_output\n    x=BatchNormalization(axis=-1, momentum=0.99, epsilon=0.001 )(x)\n    x=Dense(1024,activation='relu')(x)\n    outputs=Dense(class_count, activation='sigmoid')(x)\n\n    \n#     outputs = model_back_end.output\n    model = Model(inputs=inputs, outputs=outputs)\n    model.compile(Adamax(learning_rate=0.01), loss='binary_crossentropy', metrics=['accuracy']) \n#     else:\n#         print('Model: ', 'VOneNet')\n#         model = vone_block\n\n    model.image_size = image_size\n    model.visual_degrees = visual_degrees\n    model.gabor_parms = gabor_params\n    model.arch_params = arch_params\n\n    return model\n","metadata":{"execution":{"iopub.status.busy":"2023-05-07T02:08:12.257259Z","iopub.execute_input":"2023-05-07T02:08:12.258003Z","iopub.status.idle":"2023-05-07T02:08:12.294788Z","shell.execute_reply.started":"2023-05-07T02:08:12.257945Z","shell.execute_reply":"2023-05-07T02:08:12.293793Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# <center>VOneNet_with_8_GFBs</center>","metadata":{}},{"cell_type":"code","source":"  \nclass VOneBlock_Eight_GFBs(layers.Layer):\n    def __init__(self, sf, theta, sigx, sigy, phase,\n                 k_exc=25, noise_mode=None, noise_scale=1, noise_level=1,\n                 simple_channels=128, complex_channels=128, ksize=25, stride=4, input_size=224):\n        super().__init__()\n\n        self.in_channels = 3\n        self.simple_channels = simple_channels\n        self.complex_channels = complex_channels\n        self.out_channels = simple_channels + complex_channels\n        self.stride = stride\n        self.input_size = input_size\n\n        self.sf = sf\n        self.theta = theta\n        self.sigx = sigx\n        self.sigy = sigy\n        self.phase = phase\n        self.k_exc = k_exc\n\n        self.set_noise_mode(noise_mode, noise_scale, noise_level)\n        self.fixed_noise = None\n\n        self.simple_conv_q0 = GFB(\n            self.in_channels, self.out_channels, ksize, stride)\n        self.simple_conv_q1 = GFB(\n            self.in_channels, self.out_channels, ksize, stride)\n        self.simple_conv_q2 = GFB(\n            self.in_channels, self.out_channels, ksize, stride)\n        self.simple_conv_q3 = GFB(\n            self.in_channels, self.out_channels, ksize, stride)\n        \n        self.simple_conv_q4 = GFB(\n            self.in_channels, self.out_channels, ksize, stride)\n        self.simple_conv_q5 = GFB(\n            self.in_channels, self.out_channels, ksize, stride)\n        self.simple_conv_q6 = GFB(\n            self.in_channels, self.out_channels, ksize, stride)\n        self.simple_conv_q7 = GFB(\n            self.in_channels, self.out_channels, ksize, stride)\n        \n        self.simple_conv_q0.initialize(sf=self.sf, theta=self.theta, sigx=self.sigx, sigy=self.sigy,\n                                       phase=self.phase)\n        self.simple_conv_q1.initialize(sf=self.sf, theta=self.theta, sigx=self.sigx, sigy=self.sigy,\n                                       phase=self.phase + np.pi / 8)\n        self.simple_conv_q2.initialize(sf=self.sf, theta=self.theta, sigx=self.sigx, sigy=self.sigy,\n                                       phase=self.phase + np.pi * 2 / 8)\n        self.simple_conv_q3.initialize(sf=self.sf, theta=self.theta, sigx=self.sigx, sigy=self.sigy,\n                                       phase=self.phase + np.pi * 3 / 8)\n        self.simple_conv_q4.initialize(sf=self.sf, theta=self.theta, sigx=self.sigx, sigy=self.sigy,\n                                       phase=self.phase + np.pi * 4 / 8)\n        self.simple_conv_q5.initialize(sf=self.sf, theta=self.theta, sigx=self.sigx, sigy=self.sigy,\n                                       phase=self.phase + np.pi * 5 / 8)\n        self.simple_conv_q6.initialize(sf=self.sf, theta=self.theta, sigx=self.sigx, sigy=self.sigy,\n                                       phase=self.phase + np.pi * 6 / 8)\n        self.simple_conv_q7.initialize(sf=self.sf, theta=self.theta, sigx=self.sigx, sigy=self.sigy,\n                                       phase=self.phase + np.pi * 7 / 8)\n\n        self.simple = layers.ReLU()\n        self.complex = Identity()\n        self.gabors = Identity()\n        self.noise = layers.ReLU()\n        self.output_layer = Identity()\n\n    def call(self, inputs):\n        x = self.gabors_f(inputs)\n        x = self.noise_f(x)\n        x = self.output_layer(x)\n        return x\n\n    def gabors_f(self, inputs):\n        s_q0 = self.simple_conv_q0(inputs)\n        s_q1 = self.simple_conv_q1(inputs)\n        s_q2 = self.simple_conv_q2(inputs)\n        s_q3 = self.simple_conv_q3(inputs)\n        s_q4 = self.simple_conv_q4(inputs)\n        s_q5 = self.simple_conv_q5(inputs)\n        s_q6 = self.simple_conv_q6(inputs)\n        s_q7 = self.simple_conv_q7(inputs)\n        c = self.complex(tf.math.sqrt(s_q0[:, :, :, self.simple_channels:] ** 2 +\n                                      s_q1[:, :, :, self.simple_channels:] ** 2 +\n                                      s_q2[:, :, :, self.simple_channels:] ** 2 +\n                                      s_q3[:, :, :, self.simple_channels:] ** 2 +\n                                      s_q4[:, :, :, self.simple_channels:] ** 2 +\n                                      s_q5[:, :, :, self.simple_channels:] ** 2 +\n                                      s_q6[:, :, :, self.simple_channels:] ** 2 +\n                                      s_q7[:, :, :, self.simple_channels:] ** 2 ) / np.sqrt(8))\n        s = self.simple(s_q0[:, :, :, :self.simple_channels])\n\n        return self.gabors(self.k_exc * tf.concat((s, c), axis=-1))\n\n    def noise_f(self, inputs):\n        x = inputs\n        if self.noise_mode == 'neuronal':\n            eps = 10e-5\n            x *= self.noise_scale\n            x += self.noise_level\n            if self.fixed_noise is not None:\n                x += self.fixed_noise * tf.math.sqrt(tf.nn.relu(x) + eps)\n            else:\n                x += tf.random.normal(tf.shape(x), stddev=1) * \\\n                    tf.math.sqrt(tf.nn.relu(x) + eps)\n            x -= self.noise_level\n            x /= self.noise_scale\n        if self.noise_mode == 'gaussian':\n            if self.fixed_noise is not None:\n                x += self.fixed_noise * self.noise_scale\n            else:\n                x += tf.random.normal(tf.shape(x), stddev=1) * self.noise_scale\n        return self.noise(x)\n\n    def set_noise_mode(self, noise_mode=None, noise_scale=1, noise_level=1):\n        self.noise_mode = noise_mode\n        self.noise_scale = noise_scale\n        self.noise_level = noise_level\n\n    def fix_noise(self, batch_size=256, seed=None):\n        if seed:\n            tf.random.set_seed(seed)\n        noise_mean = tf.zeros((batch_size, int(\n            self.input_size / self.stride), int(self.input_size / self.stride), self.out_channels))\n        if self.noise_mode:\n            self.fixed_noise = tf.random.normal(noise_mean.shape, stddev=1)\n\n    def unfix_noise(self):\n        self.fixed_noise = None\n\n        \n        \n        \n        \n        \n        \n\n\ndef VOneNet_with_eight_GFBs(sf_corr=0.75, sf_max=9, sf_min=0, rand_param=False, gabor_seed=0,\n            simple_channels=256, complex_channels=256,\n            noise_mode='neuronal', noise_scale=0.35, noise_level=0.07, k_exc=25,\n            model_arch='resnet50', image_size=300, visual_degrees=8, ksize=25, stride=4, class_count=14):\n\n    out_channels = simple_channels + complex_channels\n\n    sf, theta, phase, nx, ny = generate_gabor_param(\n        out_channels, gabor_seed, rand_param, sf_corr, sf_max, sf_min)\n\n    gabor_params = {'simple_channels': simple_channels, 'complex_channels': complex_channels, 'rand_param': rand_param,\n                    'gabor_seed': gabor_seed, 'sf_max': sf_max, 'sf_corr': sf_corr, 'sf': sf.copy(),\n                    'theta': theta.copy(), 'phase': phase.copy(), 'nx': nx.copy(), 'ny': ny.copy()}\n    arch_params = {'k_exc': k_exc, 'arch': model_arch,\n                   'ksize': ksize, 'stride': stride}\n\n    # Conversions\n    ppd = image_size / visual_degrees\n\n    sf = sf / ppd\n    sigx = nx / sf\n    sigy = ny / sf\n    theta = theta/180 * np.pi\n    phase = phase / 180 * np.pi\n\n    vone_block = VOneBlock_Eight_GFBs(sf=sf, theta=theta, sigx=sigx, sigy=sigy, phase=phase,\n                           k_exc=k_exc, noise_mode=noise_mode, noise_scale=noise_scale, noise_level=noise_level,\n                           simple_channels=simple_channels, complex_channels=complex_channels,\n                           ksize=ksize, stride=stride, input_size=image_size)\n    \n    \n    \n    \n    img_shape=(image_size,image_size,3)\n#     model_back_end=tf.keras.applications.efficientnet.EfficientNetB0(include_top=False, weights=\"imagenet\",input_shape=img_shape, pooling='max')\n    \n#     inputs = tf.keras.Input(shape=(image_size, image_size, 3))\n#     x = vone_block(inputs)\n    \n    \n#     if model_arch:\n    bottleneck = Conv2D(3, kernel_size=1, strides=1, use_bias=False,kernel_initializer=tf.keras.initializers.HeNormal())\n\n#         # if model_arch.lower() == 'resnet50':\n#         #     print('Model: ', 'VOneResnet50')\n#         #     model_back_end = ResNetBackEnd(\n#         #         block=Bottleneck, layers=[3, 4, 6, 3])\n#         # elif model_arch.lower() == 'alexnet':\n#         #     print('Model: ', 'VOneAlexNet')\n#         #     model_back_end = AlexNetBackEnd()\n#         # elif model_arch.lower() == 'cornets':\n#         #     print('Model: ', 'VOneCORnet-S')\n#         #     model_back_end = CORnetSBackEnd()\n#         # TODO: change model_back_end to our block\n\n    inputs = tf.keras.Input(shape=(image_size, image_size, 3))\n    x = vone_block(inputs)\n    x = bottleneck(x)\n    \n    \n    # 获取模型后端的输入张量\n#     backend_input = model_back_end.input\n\n#     print(x.shape)\n#     assert(False)\n    \n    \n    model_back_end=tf.keras.applications.efficientnet.EfficientNetB0(include_top=False, weights=\"imagenet\",input_shape=x.shape[1:], pooling='max')\n    model_back_end.trainable = True\n#     print(backend_input.shape)\n\n    \n    # 用 bottleneck 的输出替换模型后端的输入张量\n    backend_output = model_back_end(x)\n    \n    \n    x=backend_output\n    x=BatchNormalization(axis=-1, momentum=0.99, epsilon=0.001 )(x)\n    x=Dense(1024,activation='relu')(x)\n    outputs=Dense(class_count, activation='sigmoid')(x)\n\n    \n#     outputs = model_back_end.output\n    model = Model(inputs=inputs, outputs=outputs)\n    model.compile(Adamax(learning_rate=0.01), loss='binary_crossentropy', metrics=['accuracy']) \n#     else:\n#         print('Model: ', 'VOneNet')\n#         model = vone_block\n\n    model.image_size = image_size\n    model.visual_degrees = visual_degrees\n    model.gabor_parms = gabor_params\n    model.arch_params = arch_params\n\n    return model\n","metadata":{"execution":{"iopub.status.busy":"2023-05-07T02:08:12.296294Z","iopub.execute_input":"2023-05-07T02:08:12.297554Z","iopub.status.idle":"2023-05-07T02:08:12.342605Z","shell.execute_reply.started":"2023-05-07T02:08:12.297496Z","shell.execute_reply":"2023-05-07T02:08:12.341587Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# <center>VOneNet_with_16_GFBs</center>","metadata":{}},{"cell_type":"code","source":"\nclass VOneBlock_16_GFBs(layers.Layer):\n    def __init__(self, sf, theta, sigx, sigy, phase,\n                 k_exc=25, noise_mode=None, noise_scale=1, noise_level=1,\n                 simple_channels=128, complex_channels=128, ksize=25, stride=4, input_size=224):\n        super().__init__()\n\n        self.in_channels = 3\n        self.simple_channels = simple_channels\n        self.complex_channels = complex_channels\n        self.out_channels = simple_channels + complex_channels\n        self.stride = stride\n        self.input_size = input_size\n\n        self.sf = sf\n        self.theta = theta\n        self.sigx = sigx\n        self.sigy = sigy\n        self.phase = phase\n        self.k_exc = k_exc\n\n        self.set_noise_mode(noise_mode, noise_scale, noise_level)\n        self.fixed_noise = None\n\n        self.simple_conv_q0 = GFB(\n            self.in_channels, self.out_channels, ksize, stride)\n        self.simple_conv_q1 = GFB(\n            self.in_channels, self.out_channels, ksize, stride)\n        self.simple_conv_q2 = GFB(\n            self.in_channels, self.out_channels, ksize, stride)\n        self.simple_conv_q3 = GFB(\n            self.in_channels, self.out_channels, ksize, stride)\n        \n        self.simple_conv_q4 = GFB(\n            self.in_channels, self.out_channels, ksize, stride)\n        self.simple_conv_q5 = GFB(\n            self.in_channels, self.out_channels, ksize, stride)\n        self.simple_conv_q6 = GFB(\n            self.in_channels, self.out_channels, ksize, stride)\n        self.simple_conv_q7 = GFB(\n            self.in_channels, self.out_channels, ksize, stride)\n        \n        \n        self.simple_conv_q8 = GFB(\n            self.in_channels, self.out_channels, ksize, stride)\n        self.simple_conv_q9 = GFB(\n            self.in_channels, self.out_channels, ksize, stride)\n        self.simple_conv_q10 = GFB(\n            self.in_channels, self.out_channels, ksize, stride)\n        self.simple_conv_q11 = GFB(\n            self.in_channels, self.out_channels, ksize, stride)\n        \n        self.simple_conv_q12 = GFB(\n            self.in_channels, self.out_channels, ksize, stride)\n        self.simple_conv_q13 = GFB(\n            self.in_channels, self.out_channels, ksize, stride)\n        self.simple_conv_q14 = GFB(\n            self.in_channels, self.out_channels, ksize, stride)\n        self.simple_conv_q15 = GFB(\n            self.in_channels, self.out_channels, ksize, stride)\n        \n        self.simple_conv_q0.initialize(sf=self.sf, theta=self.theta, sigx=self.sigx, sigy=self.sigy,\n                                       phase=self.phase)\n        self.simple_conv_q1.initialize(sf=self.sf, theta=self.theta, sigx=self.sigx, sigy=self.sigy,\n                                       phase=self.phase + np.pi / 16)\n        self.simple_conv_q2.initialize(sf=self.sf, theta=self.theta, sigx=self.sigx, sigy=self.sigy,\n                                       phase=self.phase + np.pi * 2 / 16)\n        self.simple_conv_q3.initialize(sf=self.sf, theta=self.theta, sigx=self.sigx, sigy=self.sigy,\n                                       phase=self.phase + np.pi * 3 / 16)\n        self.simple_conv_q4.initialize(sf=self.sf, theta=self.theta, sigx=self.sigx, sigy=self.sigy,\n                                       phase=self.phase + np.pi * 4 / 16)\n        self.simple_conv_q5.initialize(sf=self.sf, theta=self.theta, sigx=self.sigx, sigy=self.sigy,\n                                       phase=self.phase + np.pi * 5 / 16)\n        self.simple_conv_q6.initialize(sf=self.sf, theta=self.theta, sigx=self.sigx, sigy=self.sigy,\n                                       phase=self.phase + np.pi * 6 / 16)\n        self.simple_conv_q7.initialize(sf=self.sf, theta=self.theta, sigx=self.sigx, sigy=self.sigy,\n                                       phase=self.phase + np.pi * 7 / 16)\n        \n        \n        \n        self.simple_conv_q8.initialize(sf=self.sf, theta=self.theta, sigx=self.sigx, sigy=self.sigy,\n                                       phase=self.phase + np.pi * 8 / 16)\n        self.simple_conv_q9.initialize(sf=self.sf, theta=self.theta, sigx=self.sigx, sigy=self.sigy,\n                                       phase=self.phase + np.pi * 9 / 16)\n        self.simple_conv_q10.initialize(sf=self.sf, theta=self.theta, sigx=self.sigx, sigy=self.sigy,\n                                       phase=self.phase + np.pi * 10 / 16)\n        self.simple_conv_q11.initialize(sf=self.sf, theta=self.theta, sigx=self.sigx, sigy=self.sigy,\n                                       phase=self.phase + np.pi * 11 / 16)\n        self.simple_conv_q12.initialize(sf=self.sf, theta=self.theta, sigx=self.sigx, sigy=self.sigy,\n                                       phase=self.phase + np.pi * 12 / 16)\n        self.simple_conv_q13.initialize(sf=self.sf, theta=self.theta, sigx=self.sigx, sigy=self.sigy,\n                                       phase=self.phase + np.pi * 13 / 16)\n        self.simple_conv_q14.initialize(sf=self.sf, theta=self.theta, sigx=self.sigx, sigy=self.sigy,\n                                       phase=self.phase + np.pi * 14 / 16)\n        self.simple_conv_q15.initialize(sf=self.sf, theta=self.theta, sigx=self.sigx, sigy=self.sigy,\n                                       phase=self.phase + np.pi * 15 / 16)\n\n        self.simple = layers.ReLU()\n        self.complex = Identity()\n        self.gabors = Identity()\n        self.noise = layers.ReLU()\n        self.output_layer = Identity()\n\n    def call(self, inputs):\n        x = self.gabors_f(inputs)\n        x = self.noise_f(x)\n        x = self.output_layer(x)\n        return x\n\n    def gabors_f(self, inputs):\n        s_q0 = self.simple_conv_q0(inputs)\n        s_q1 = self.simple_conv_q1(inputs)\n        s_q2 = self.simple_conv_q2(inputs)\n        s_q3 = self.simple_conv_q3(inputs)\n        s_q4 = self.simple_conv_q4(inputs)\n        s_q5 = self.simple_conv_q5(inputs)\n        s_q6 = self.simple_conv_q6(inputs)\n        s_q7 = self.simple_conv_q7(inputs)\n        \n        \n        s_q8 = self.simple_conv_q8(inputs)\n        s_q9 = self.simple_conv_q9(inputs)\n        s_q10 = self.simple_conv_q10(inputs)\n        s_q11 = self.simple_conv_q11(inputs)\n        s_q12 = self.simple_conv_q12(inputs)\n        s_q13 = self.simple_conv_q13(inputs)\n        s_q14 = self.simple_conv_q14(inputs)\n        s_q15 = self.simple_conv_q15(inputs)\n        \n        c = self.complex(tf.math.sqrt(s_q0[:, :, :, self.simple_channels:] ** 2 +\n                                      s_q1[:, :, :, self.simple_channels:] ** 2 +\n                                      s_q2[:, :, :, self.simple_channels:] ** 2 +\n                                      s_q3[:, :, :, self.simple_channels:] ** 2 +\n                                      s_q4[:, :, :, self.simple_channels:] ** 2 +\n                                      s_q5[:, :, :, self.simple_channels:] ** 2 +\n                                      s_q6[:, :, :, self.simple_channels:] ** 2 +\n                                      s_q7[:, :, :, self.simple_channels:] ** 2 +\n                                      s_q8[:, :, :, self.simple_channels:] ** 2 +\n                                      s_q9[:, :, :, self.simple_channels:] ** 2 +\n                                      s_q10[:, :, :, self.simple_channels:] ** 2 +\n                                      s_q11[:, :, :, self.simple_channels:] ** 2 +\n                                      s_q12[:, :, :, self.simple_channels:] ** 2 +\n                                      s_q13[:, :, :, self.simple_channels:] ** 2 +\n                                      s_q14[:, :, :, self.simple_channels:] ** 2 +\n                                      s_q15[:, :, :, self.simple_channels:] ** 2\n                                     \n                                     \n                                     ) / np.sqrt(16))\n        s = self.simple(s_q0[:, :, :, :self.simple_channels])\n\n        return self.gabors(self.k_exc * tf.concat((s, c), axis=-1))\n\n    def noise_f(self, inputs):\n        x = inputs\n        if self.noise_mode == 'neuronal':\n            eps = 10e-5\n            x *= self.noise_scale\n            x += self.noise_level\n            if self.fixed_noise is not None:\n                x += self.fixed_noise * tf.math.sqrt(tf.nn.relu(x) + eps)\n            else:\n                x += tf.random.normal(tf.shape(x), stddev=1) * \\\n                    tf.math.sqrt(tf.nn.relu(x) + eps)\n            x -= self.noise_level\n            x /= self.noise_scale\n        if self.noise_mode == 'gaussian':\n            if self.fixed_noise is not None:\n                x += self.fixed_noise * self.noise_scale\n            else:\n                x += tf.random.normal(tf.shape(x), stddev=1) * self.noise_scale\n        return self.noise(x)\n\n    def set_noise_mode(self, noise_mode=None, noise_scale=1, noise_level=1):\n        self.noise_mode = noise_mode\n        self.noise_scale = noise_scale\n        self.noise_level = noise_level\n\n    def fix_noise(self, batch_size=256, seed=None):\n        if seed:\n            tf.random.set_seed(seed)\n        noise_mean = tf.zeros((batch_size, int(\n            self.input_size / self.stride), int(self.input_size / self.stride), self.out_channels))\n        if self.noise_mode:\n            self.fixed_noise = tf.random.normal(noise_mean.shape, stddev=1)\n\n    def unfix_noise(self):\n        self.fixed_noise = None\n\n        \n        \n        \n        \n        \n        \n\n\ndef VOneNet_with_16_GFBs(sf_corr=0.75, sf_max=9, sf_min=0, rand_param=False, gabor_seed=0,\n            simple_channels=256, complex_channels=256,\n            noise_mode='neuronal', noise_scale=0.35, noise_level=0.07, k_exc=25,\n            model_arch='resnet50', image_size=300, visual_degrees=8, ksize=25, stride=4, class_count=14):\n\n    out_channels = simple_channels + complex_channels\n\n    sf, theta, phase, nx, ny = generate_gabor_param(\n        out_channels, gabor_seed, rand_param, sf_corr, sf_max, sf_min)\n\n    gabor_params = {'simple_channels': simple_channels, 'complex_channels': complex_channels, 'rand_param': rand_param,\n                    'gabor_seed': gabor_seed, 'sf_max': sf_max, 'sf_corr': sf_corr, 'sf': sf.copy(),\n                    'theta': theta.copy(), 'phase': phase.copy(), 'nx': nx.copy(), 'ny': ny.copy()}\n    arch_params = {'k_exc': k_exc, 'arch': model_arch,\n                   'ksize': ksize, 'stride': stride}\n\n    # Conversions\n    ppd = image_size / visual_degrees\n\n    sf = sf / ppd\n    sigx = nx / sf\n    sigy = ny / sf\n    theta = theta/180 * np.pi\n    phase = phase / 180 * np.pi\n\n    vone_block = VOneBlock_16_GFBs(sf=sf, theta=theta, sigx=sigx, sigy=sigy, phase=phase,\n                           k_exc=k_exc, noise_mode=noise_mode, noise_scale=noise_scale, noise_level=noise_level,\n                           simple_channels=simple_channels, complex_channels=complex_channels,\n                           ksize=ksize, stride=stride, input_size=image_size)\n    \n    \n    \n    \n    img_shape=(image_size,image_size,3)\n#     model_back_end=tf.keras.applications.efficientnet.EfficientNetB0(include_top=False, weights=\"imagenet\",input_shape=img_shape, pooling='max')\n    \n#     inputs = tf.keras.Input(shape=(image_size, image_size, 3))\n#     x = vone_block(inputs)\n    \n    \n#     if model_arch:\n    bottleneck = Conv2D(3, kernel_size=1, strides=1, use_bias=False,kernel_initializer=tf.keras.initializers.HeNormal())\n\n#         # if model_arch.lower() == 'resnet50':\n#         #     print('Model: ', 'VOneResnet50')\n#         #     model_back_end = ResNetBackEnd(\n#         #         block=Bottleneck, layers=[3, 4, 6, 3])\n#         # elif model_arch.lower() == 'alexnet':\n#         #     print('Model: ', 'VOneAlexNet')\n#         #     model_back_end = AlexNetBackEnd()\n#         # elif model_arch.lower() == 'cornets':\n#         #     print('Model: ', 'VOneCORnet-S')\n#         #     model_back_end = CORnetSBackEnd()\n#         # TODO: change model_back_end to our block\n\n    inputs = tf.keras.Input(shape=(image_size, image_size, 3))\n    x = vone_block(inputs)\n    x = bottleneck(x)\n    \n    \n    # 获取模型后端的输入张量\n#     backend_input = model_back_end.input\n\n#     print(x.shape)\n#     assert(False)\n    \n    \n    model_back_end=tf.keras.applications.efficientnet.EfficientNetB0(include_top=False, weights=\"imagenet\",input_shape=x.shape[1:], pooling='max')\n    model_back_end.trainable = True\n#     print(backend_input.shape)\n\n    \n    # 用 bottleneck 的输出替换模型后端的输入张量\n    backend_output = model_back_end(x)\n    \n    \n    x=backend_output\n    x=BatchNormalization(axis=-1, momentum=0.99, epsilon=0.001 )(x)\n    x=Dense(1024,activation='relu')(x)\n    outputs=Dense(class_count, activation='sigmoid')(x)\n\n    \n#     outputs = model_back_end.output\n    model = Model(inputs=inputs, outputs=outputs)\n    model.compile(Adamax(learning_rate=0.01), loss='binary_crossentropy', metrics=['accuracy']) \n#     else:\n#         print('Model: ', 'VOneNet')\n#         model = vone_block\n\n    model.image_size = image_size\n    model.visual_degrees = visual_degrees\n    model.gabor_parms = gabor_params\n    model.arch_params = arch_params\n\n    return model","metadata":{"execution":{"iopub.status.busy":"2023-05-07T02:08:12.346048Z","iopub.execute_input":"2023-05-07T02:08:12.346688Z","iopub.status.idle":"2023-05-07T02:08:12.399841Z","shell.execute_reply.started":"2023-05-07T02:08:12.346637Z","shell.execute_reply":"2023-05-07T02:08:12.398680Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# <center>Data Preprocessing</center>","metadata":{}},{"cell_type":"code","source":"# This is the kaggle dataset path\ndatapath=r'../input/pizza-images-with-topping-labels/pizza_data/labels.csv'\nimgpath=r'../input/pizza-images-with-topping-labels/pizza_data/images'\n\n# datapath=r'pizza_data/labels.csv'\n# imgpath=r'pizza_data/images'\ndf=pd.read_csv(datapath)\ndf=df.sample(n=9000, replace=False, random_state = 1)\ndf['plain']=0\ncolumns=df.columns\n\ndf['image_name']=df['image_name'].apply(lambda x: os.path.join(imgpath,x))\ndf = df.rename(columns={'image_name': 'filepaths'})\n\nfor i in range (len(df)):\n    label_list=[]\n    for j in range (1,len(df.columns)-1):\n        column=df.columns[j]        \n        label=df.iloc[i][column]\n        label_list.append(label)\n    max=np.max(label_list)        \n    if max == 0:         \n        df['plain'].iloc[i]=1\ntrain_df, dummy_df=train_test_split(df, train_size=.8, shuffle=True, random_state=123)\nvalid_df, test_df=train_test_split(dummy_df, train_size=.5, shuffle=True, random_state=123)\nprint('train_df length: ', len(train_df), '  test_df length: ', len(test_df), '  valid_df length: ', len(valid_df)) ","metadata":{"execution":{"iopub.status.busy":"2023-05-07T02:08:12.401444Z","iopub.execute_input":"2023-05-07T02:08:12.401905Z","iopub.status.idle":"2023-05-07T02:08:29.188214Z","shell.execute_reply.started":"2023-05-07T02:08:12.401865Z","shell.execute_reply":"2023-05-07T02:08:29.186117Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"img_size=(300,300)\ncolumns=df.columns[1:]\nclass_count=len(columns)\ngenerator=ImageDataGenerator()\ntrain=generator.flow_from_dataframe(train_df, x_col='filepaths', y_col=columns, target_size=img_size, batch_size=30,shuffle=True,seed=123, class_mode='raw')\nval=generator.flow_from_dataframe(valid_df, x_col='filepaths', y_col=columns, target_size=img_size, batch_size=30,shuffle=False,class_mode='raw')\ntest=generator.flow_from_dataframe(valid_df, x_col='filepaths', y_col=columns, target_size=img_size, batch_size=30,shuffle=False,class_mode='raw')","metadata":{"execution":{"iopub.status.busy":"2023-05-07T02:08:29.189750Z","iopub.execute_input":"2023-05-07T02:08:29.190088Z","iopub.status.idle":"2023-05-07T02:08:58.962856Z","shell.execute_reply.started":"2023-05-07T02:08:29.190061Z","shell.execute_reply":"2023-05-07T02:08:58.961656Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# <center>Display Sample Images</center>","metadata":{}},{"cell_type":"code","source":"def display_samples(img, classes): \n    images,labels=next(img)\n    plt.figure(figsize=(25, 25))\n    num_of_images=10\n    for i in range(num_of_images):        \n        plt.subplot(5, 5, i + 1)\n        image=images[i] /255 \n        label=labels[i]\n        title=''\n        for j in range(len(label)):\n            value=label[j]\n            if value == 1:\n                title=title + ' '+ classes[j]\n        plt.imshow(image)\n        fname=os.path.basename(img.filenames[i])        \n        plt.title(title, fontsize=15)\n    plt.show()\n    \ndisplay_samples(train, columns )","metadata":{"execution":{"iopub.status.busy":"2023-05-07T02:08:58.964711Z","iopub.execute_input":"2023-05-07T02:08:58.965471Z","iopub.status.idle":"2023-05-07T02:09:01.918351Z","shell.execute_reply.started":"2023-05-07T02:08:58.965433Z","shell.execute_reply":"2023-05-07T02:09:01.916967Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# <center>Run & train the Model</center>","metadata":{}},{"cell_type":"code","source":"lr=.001\n# model=VOneNet()\n# model=VOneNet_with_four_GFBs()\n# model=VOneNet_with_eight_GFBs()\nmodel=VOneNet_with_Only_Simple_GFBs()\n# model=EfficientNet_B0_Dense1024(img_size, lr, class_count)","metadata":{"execution":{"iopub.status.busy":"2023-05-07T02:09:02.244891Z","iopub.execute_input":"2023-05-07T02:09:02.245340Z","iopub.status.idle":"2023-05-07T02:09:16.395691Z","shell.execute_reply.started":"2023-05-07T02:09:02.245303Z","shell.execute_reply":"2023-05-07T02:09:16.394562Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"epochs=50","metadata":{"execution":{"iopub.status.busy":"2023-05-07T02:09:16.397304Z","iopub.execute_input":"2023-05-07T02:09:16.397687Z","iopub.status.idle":"2023-05-07T02:09:16.402452Z","shell.execute_reply.started":"2023-05-07T02:09:16.397647Z","shell.execute_reply":"2023-05-07T02:09:16.401394Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history=model.fit(x=train,  epochs=epochs, verbose=1, validation_data=val, shuffle=True,  initial_epoch=0)","metadata":{"execution":{"iopub.status.busy":"2023-05-07T02:09:16.403888Z","iopub.execute_input":"2023-05-07T02:09:16.404541Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.save_weights('/kaggle/working/ModelOutput')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# <center>Visualization \\& Evaluation</center>","metadata":{}},{"cell_type":"code","source":"def tr_plot(tr_data, start_epoch):\n    tacc=tr_data.history['accuracy']\n    tloss=tr_data.history['loss']\n    vacc=tr_data.history['val_accuracy']\n    vloss=tr_data.history['val_loss']\n    Epoch_count=len(tacc)+ start_epoch\n    Epochs=[]\n    for i in range (start_epoch ,Epoch_count):\n        Epochs.append(i+1)   \n    index_loss=np.argmin(vloss)\n    val_lowest=vloss[index_loss]\n    index_acc=np.argmax(vacc)\n    acc_highest=vacc[index_acc]\n    plt.style.use('fivethirtyeight')\n    sc_label='best epoch= '+ str(index_loss+1 +start_epoch)\n    vc_label='best epoch= '+ str(index_acc + 1+ start_epoch)\n    fig,axes=plt.subplots(nrows=1, ncols=2, figsize=(25,10))\n    axes[0].plot(Epochs,tloss, 'r', label='Training loss')\n    axes[0].plot(Epochs,vloss,'g',label='Validation loss' )\n    axes[0].scatter(index_loss+1 +start_epoch,val_lowest, s=150, c= 'blue', label=sc_label)\n    axes[0].scatter(Epochs, tloss, s=100, c='red')    \n    axes[0].set_title('Training and Validation Loss')\n    axes[0].set_xlabel('Epochs', fontsize=18)\n    axes[0].set_ylabel('Loss', fontsize=18)\n    axes[0].legend()\n    axes[1].plot (Epochs,tacc,'r',label= 'Training Accuracy')\n    axes[1].scatter(Epochs, tacc, s=100, c='red')\n    axes[1].plot (Epochs,vacc,'g',label= 'Validation Accuracy')\n    axes[1].scatter(index_acc+1 +start_epoch,acc_highest, s=150, c= 'blue', label=vc_label)\n    axes[1].set_title('Training and Validation Accuracy')\n    axes[1].set_xlabel('Epochs', fontsize=18)\n    axes[1].set_ylabel('Accuracy', fontsize=18)\n    axes[1].legend()\n    plt.tight_layout    \n    plt.show()\n    return index_loss\n    \nloss_index=tr_plot(history,0)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"loss, accuracy=model.evaluate(test)\nprint (accuracy)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# <center>White Box Adversarial Attack</center>","metadata":{}},{"cell_type":"code","source":"#load the model\nlr = 0.01\n# model = EfficientNet_B0_Dense1024(img_size, lr, class_count)\nmodel = VOneNet()\nepochs=15\n# history=model.fit(x=train,  epochs=epochs, verbose=1, validation_data=val, shuffle=False,  initial_epoch=0)\nmodel.load_weights('/kaggle/input/voneefficient/ModelOutput')\n# model.save_weights('/kaggle/working/ModelOutput')\n# !mkdir /kaggle/working/output\n# !rm -rf /kaggle/working/*","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Generate the FGSM attack\n!rm -rf /kaggle/working/output\n!mkdir /kaggle/working/output\nimport pandas as pd\nimport os\nimport tensorflow as tf\nfrom keras.preprocessing.image import array_to_img\nfrom PIL import Image\n\n#Generate the label according to the labels.csv\ndef label_preprocess(filepath):\n    mask = df[\"filepaths\"] == filepath\n    matching_rows = df[mask]\n    if matching_rows.shape[0] == 0:\n        print(\"Not found\")\n        return \n    else:\n        label = []\n        for i in range(1,15):\n            label.append(matching_rows.iloc[0,i])\n        return label\n    \n#Generate the adversarial attack images. input image is a Image object, output is a numpy\ndef fgsm_attack(image, epsilon, pred, model): \n    # Create a tensor from the input image\n    img_tensor = tf.keras.preprocessing.image.img_to_array(image)\n    if img_tensor.shape[-1] !=3:\n        return None, False\n    # Add a batch dimension\n    img_tensor = np.expand_dims(img_tensor, axis=0)\n\n    # Create a tensor from the input image\n    input_tensor = tf.convert_to_tensor(img_tensor)\n\n    # Watch the input tensor with GradientTape\n    with tf.GradientTape() as tape:\n        tape.watch(input_tensor)\n\n        # Get the output of the model\n        output = model(input_tensor)\n        # Compute the loss\n        loss = tf.keras.losses.binary_crossentropy(pred, output)\n\n    # Get the gradient of the loss with respect to the input tensor\n    gradient = tape.gradient(loss, input_tensor)\n\n    # Get the sign of the gradient\n    signed_gradient = tf.sign(gradient)\n\n    # Add the sign of the gradient to the input tensor to generate the perturbation\n    perturbed_tensor = input_tensor + epsilon * signed_gradient\n\n    # Clip the perturbed tensor to ensure it stays within the valid pixel range\n    perturbed_tensor = tf.clip_by_value(perturbed_tensor, 0, 255)\n\n    # Convert the perturbed tensor back to an array\n    perturbed_array = np.array(perturbed_tensor)\n\n    # Remove the batch dimension\n    perturbed_array = np.squeeze(perturbed_array, axis=0)\n#     print(perturbed_array.shape)\n    # Convert the array to a PIL Image\n#     perturbed_image = Image.fromarray(np.int8(perturbed_array*255))\n\n    return perturbed_array, True\n\ndef generate_adv(model, input_dir = '../input/pizza-images-with-topping-labels/pizza_data/images/', output_dir= '../working/output', eps = 0.1):\n    # Loop through each file in the input directory\n    i=0\n    for filename in os.listdir(input_dir):\n        # Check if the file is a .jpg image\n        if filename.endswith('.jpg'):\n            i+=1\n            if i%10 == 0:\n                print(i)\n            if i==500:\n                break\n            # Load the image\n            image_path = os.path.join(input_dir, filename)\n    #         print(image_path)\n            img = Image.open(image_path)\n            img = img.resize((300,300))\n            pred = label_preprocess(image_path)\n            pred = np.expand_dims(pred, axis=0)\n            # Generate an adversarial example with epsilon = 0.1\n            adv_img, flag = fgsm_attack(img, eps, pred, model)\n            if flag == False:\n                print(f\"Format incorrect: {filename}\")\n                continue\n    #         print(adv_img.shape)\n            adv_img = Image.fromarray(np.uint8(adv_img))\n            # Save the adversarial example to disk\n            adv_img.save('/kaggle/working/output/'+filename)\n\ndef main():\n    #Hyperparameters\n    lr = 0.001\n    #Here indicate the model you want to attack\n    model = EfficientNet_B0_Dense1024(img_size, lr, class_count)\n    epochs=15\n    #input directory\n    input_dir = '../input/pizza-images-with-topping-labels/pizza_data/images/'\n    #output directory\n    output_dir = '../working/output'\n    model.load_weights('/kaggle/input/efficientnet/ModelOutput')\n    \n    #generate adversarial images\n    generate_adv(model, input_dir, output_dir, eps = 25.0)\n\nmain()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#pack up\n!tar -czvf vonenet-adv-eps5.tar.gz /kaggle/working/output","metadata":{},"execution_count":null,"outputs":[]}]}